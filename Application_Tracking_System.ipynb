{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an ATS to check the resume against the Job Description to find the probability of resume getting shortlisting and provide the result of resume getting accepted with match percentage"
      ],
      "metadata": {
        "id": "V_F8tO4a6AHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install the package that reads the document to txt"
      ],
      "metadata": {
        "id": "5DUGZtWf6OHM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr9y0DgP3JXC",
        "outputId": "0686f68c-98b6-4d94-8844-477f678eab7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=b29de861cdff99f5b0ed6dceb106b37e065a8ffd1b577a8f1424146485560380\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/f0/2c/81637d42670985178b77df6d41b9b6c6dc18c94818447414b9\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ],
      "source": [
        "pip install docx2txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing the library"
      ],
      "metadata": {
        "id": "FXaatOuw7VL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt"
      ],
      "metadata": {
        "id": "nnriWg1U3Wio"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=docx2txt.process(\"/content/Pavan_CV(DA).docx\")\n",
        "print(cv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3nJAYCp3ZCh",
        "outputId": "dd3d58db-10fa-4e80-b847-061d4c8f15cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pavan Siddihally Venugopala Reddy\n",
            "\n",
            "36, Dochart Drive, Edinburgh, EH4 7LB                                                                                                             Mobile No: +44 7361883601, +44 7760459591\n",
            "\n",
            "Email: pavanyenigi04@gmail.com\n",
            "\n",
            "LinkedIn: https://www.linkedin.com/in/pavan-y-7179ba17b/\n",
            "\n",
            "GitHub: https://github.com/PavanYenigi\n",
            "\n",
            "\n",
            "\n",
            "SUMMARY\n",
            "\n",
            "\tA versatile and passionate individual with experience collecting, transforming, and organizing data for analysis to help make informed data-driven decisions and communicate with stakeholders and customers. Excellent understanding and proficiency in platforms for effective data analysis, including Python, Microsoft SQL Server, spreadsheets, Tableau, and Power BI with strong communication, organizational and analytical skills in data-driven decision-making.\n",
            "\n",
            "\t\n",
            "\n",
            "TECHNICAL SKILLS\n",
            "\n",
            "Python\n",
            "\n",
            "Data Analysis\n",
            "\n",
            "Tableau\n",
            "\n",
            "Data Visualization\n",
            "\n",
            "Power BI\n",
            "\n",
            "Exploratory Data Analytics\n",
            "\n",
            "Microsoft Excel\n",
            "\n",
            "ETL\n",
            "\n",
            "SQL\n",
            "\n",
            "Machine Learning\n",
            "\n",
            "Flask\n",
            "\n",
            "AWS\n",
            "\n",
            "Business Analytics\n",
            "\n",
            "Natural Language Processing\n",
            "\n",
            "\n",
            "\n",
            "\tEDUCATION\t\n",
            "\n",
            "\tMaster’s in Data Science (08 February 2021 - Present)\n",
            "\n",
            "-University of Surrey, UK\n",
            "\n",
            "Course Modules: Cloud computing, Data science principles and practices, Machine Learning and Data Mining, Database systems, Artificial Intelligence, Practical Business Analytics, Information Security Management, and Computational Intelligence.\n",
            "\n",
            "\n",
            "\n",
            "PROFESSIONAL EXPERIENCE\n",
            "\n",
            "\n",
            "\n",
            "\tCompany name: Rosslyn Data Technologies                                Portsmouth, United Kingdom\n",
            "\n",
            "\tDesignation: Data Analyst Support                                                  Mar 2022 – Oct 2022\n",
            "\n",
            "\tRoles and Responsibilities\n",
            "\n",
            "\tWorking closely with the customers to provide an excellent service\n",
            "\n",
            "\tResolving the data issues of customers and helping them in analysis and generating reports\n",
            "\n",
            "\tCoordinated with Data Team and the Support Team.\n",
            "\n",
            "\tWorked closely with the data engineers and ETL developers to understand the structure of the database.\n",
            "\n",
            "\tETL testing and QA\n",
            "\n",
            "\t\tCreated SQL aggregate Functions (SUM, AVG, RANK, ROW_NUMBER) for analytical purposes.\n",
            "\n",
            "\t\tDeveloped SQL views with the specifications provided.\n",
            "\n",
            "\tMaintaining the dashboards and the data mining applications of the Rosslyn Product\n",
            "\n",
            "\tClean and validate the customer’s spend datasets.\n",
            "\n",
            "\tExtract, Transform and Load the customer monthly spend datasets into the DB\n",
            "\n",
            "\t\n",
            "\n",
            "\t\n",
            "\n",
            "\tCompany name: Head Digital Works                                                                             Bangalore, India\n",
            "\n",
            "\tDesignation: Software Test Engineer                                                                          AUG 2019 – Dec 2019 \n",
            "\n",
            "\tRoles and Responsibilities \n",
            "\n",
            "\tWorked as an automation engineer for the gaming and gambling application. \n",
            "\n",
            "\tExpertise in Java Selenium frameworks, Manual Testing, and Test Case Preparation\n",
            "\n",
            "\t Writing test cases, automating test cases, and executing the test cases manually\n",
            "\n",
            "\t Performing different types of Manual Tests like Functional, Integration, and Sanity testing \n",
            "\n",
            "\tManual testing of the application on Dev, QA, and Production environments \n",
            "\n",
            "\tWorked on a project, based on agile methodology attending and contributing to the sprint meeting and retrospect meeting to improve the processes \n",
            "\n",
            "\tRaising the bugs on Jira, assign the severity and priority. - Competitive Analysis with different competitors (Dream11, Mycricket11, MPL, Cricbuzz) and present it to the stakeholders\n",
            "\n",
            "\t\n",
            "\n",
            "\tCompany name: Cozmo Pvt Ltd                                                                          Bangalore, India\n",
            "\n",
            "\t     Designation: Data Analyst Intern                                                                          AUG 2019 – Dec 2019 \n",
            "\n",
            "\tRoles and Responsibilities\n",
            "\n",
            "\t\tAnalysing data using statistical techniques using spreadsheets and SQL\n",
            "\n",
            "\t\tDeveloped SQL scripts with the specifications provided, conforming to Coding Standards and documentation.\n",
            "\n",
            "\t\tDeveloped and Tested DML (data manipulation language), DDL, and queries with joins to simplify complex queries involving multiple tables\n",
            "\n",
            "\t\tCreated SQL aggregated Functions (SUM, AVG, RANK, ROW_NUMBER) for analytical purposes.\n",
            "\n",
            "\t\tManaging multiple projects simultaneously and performing data analysis on new and existing data sets.\n",
            "\n",
            "\t\tFiltering and cleaning data using Python.\n",
            "\n",
            "\t\tGenerating information and insights from data sets and identifying trends and patterns and converting them into meaningful insights.\n",
            "\n",
            "\t\tStorytelling through visualizations of data and dashboards using Tableau\n",
            "\n",
            "\n",
            "\n",
            "PROJECTS\n",
            "\n",
            "\n",
            "\n",
            "Real-Time Financial Complaints dashboard using Tableau\n",
            "\n",
            "Description: The financial complaints, and response rate data are used to develop a dashboard in tableau. The dashboard shows key KPIs such as total complaints, timely response, complaints in progress, and other stuff.\n",
            "\n",
            "Sales Dashboard based on sales agents using Tableau\n",
            "\n",
            "Description: Product sales, transaction data, and sales agent data are used to construct the dashboard utilizing joins in tableau. The dashboard displays the product sales of the agent every month, the top SKUs, and the top product categories and allows to set of sales targets.\n",
            "\n",
            "Sentiment Analysis Engine using Natural Language Processing\n",
            "\n",
            "Description: This project aims to perform real-time sentiment analysis of tweets using Twitter data to classify the toxicity level of comments.\n",
            "\n",
            "Link: https://github.com/PavanYenigi/Twitter-Toxic-Comment-Analysis\n",
            "\n",
            "\n",
            "\n",
            "CERTIFICATIONS\n",
            "\n",
            "\n",
            "\n",
            "\tGoogle Data Analytics Certificate\n",
            "\n",
            "\tWhat is Data Science?    -By IBM\n",
            "\n",
            "\thttps://www.sololearn.com/certificates/course/en/14540187/1073/landscape/png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jd=docx2txt.process(\"/content/SKY-DA-JD.docx\")\n",
        "print(jd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwRb3qJr3qaT",
        "outputId": "9b228a14-067c-4020-ba87-1481d012bdd7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Analyst\n",
            "\n",
            "Apply\n",
            "\n",
            "\n",
            "\n",
            "locations\n",
            "\n",
            "Osterley\n",
            "\n",
            "time type\n",
            "\n",
            "Full time\n",
            "\n",
            "posted on\n",
            "\n",
            "Posted 2 Days Ago\n",
            "\n",
            "job requisition id\n",
            "\n",
            "R0014899\n",
            "\n",
            "As a Data Analyst for Third Party Data within Sky Data you will be responsible for the support and analysis of Third Party Data products, with opportunities to contribute throughout the full product cycle.\n",
            "\n",
            "Third Party Data underpins critical insights, reporting, analysis and campaign strategy across the organisation so you will be part of the team that helps to ensure the quality and accuracy of this data, enabling us to confidently use the data we source.\n",
            "\n",
            "Core to the role, you will act as the technical lead on projects involving Third Party datasets. Managing the technical discussions and questions relating to third party data between suppliers and internal operational teams. You will also support the business with ad-hoc analytical queries, which presents a great opportunity to work closely with multiple business teams, understanding and supporting their end-to-end requirements.\n",
            "\n",
            "What you'll do\n",
            "\n",
            "Support the Lead Product Owner and Senior Analysts to deliver and continuously improve the Product offering for Third Party Data.\n",
            "\n",
            "Evaluate and interpret the quality and accuracy of Third Party Data.\n",
            "\n",
            "Identify new ways in which existing data can be used to improve return on investment from the data licensed.\n",
            "\n",
            "Educate and train internal stakeholders on the Third Party Data available with a focus on its business value and permitted use.\n",
            "\n",
            "Present your findings in a commercially focused and practical way, showing the benefits of Third Party Data.\n",
            "\n",
            "Support ad-hoc analytical requirements.\n",
            "\n",
            "What you'll bring\n",
            "\n",
            "Good understanding of analytical methodologies, specifically a working knowledge of databases, data structures and reporting systems.\n",
            "\n",
            "Understanding and experience of Cloud platforms\n",
            "\n",
            "Demonstrable experience of using SQL to analyse large, complex datasets\n",
            "\n",
            "Ability to communicate and manipulate data in a variety of tools to suit stakeholder needs – e.g. Excel, Powerpoint, Tableau (or similar)\n",
            "\n",
            "Experience of working in an Agile environment\n",
            "\n",
            "Ability to manage your workload across several projects and stakeholders simultaneously\n",
            "\n",
            "Strong communication skills\n",
            "\n",
            "Team overview: Group Data Hub\n",
            "\n",
            "Want to unlock the power of data? Our Group Data Hub works with millions of data transformations every day to deliver value, improve customer experience and enable new product launches. From architecture to analytics and engineering to science: it’s how we bring customers more of what they love.\n",
            "\n",
            "The rewards \n",
            "\n",
            "There's one thing people can't stop talking about when it comes to #LifeAtSky: the perks. Here’s a taster:\n",
            "\n",
            "Sky Q, for the TV you love all in one place\n",
            "\n",
            "The magic of Sky Glass at an exclusive rate\n",
            "\n",
            "A generous pension package\n",
            "\n",
            "Private healthcare\n",
            "\n",
            "Discounted mobile and broadband\n",
            "\n",
            "A wide range of Sky VIP rewards and experiences\n",
            "\n",
            "Inclusion & how you'll work\n",
            "\n",
            "Recognised by The Times and Stonewall, we take pride in our approach to diversity and inclusion. Investing in society, fighting racial injustice and setting ambitious targets for representation at Sky.\n",
            "\n",
            "We’ve embraced hybrid working and split our time between unique office spaces and the convenience of working from home. You’ll find out more about what hybrid working looks like for your role later on in the recruitment process.\n",
            "\n",
            "Your office space: Osterley\n",
            "\n",
            "Our Osterley Campus is a 10-minute walk from Syon Lane train station. Or you can hop on one of our free shuttle buses that run to and from Osterley, Gunnersbury, Ealing Broadway and South Ealing tube stations. There are also plenty of bike shelters and showers.\n",
            "\n",
            "On campus, you’ll find 13 subsidised restaurants, cafes, and a Waitrose. You can keep in shape at our subsidised gym, catch the latest shows and movies at our cinema, get your car washed, and even get pampered at our beauty salon.\n",
            "\n",
            "We'd love to hear from you\n",
            "\n",
            "Inventive, forward-thinking minds come together to work in Tech, Product and Data at Sky. It’s a place where you can explore what if, how far, and what next.\n",
            "\n",
            "But better doesn’t stop at what we do, it’s how we do it, too. We embrace each other’s differences. We support our community and contribute to a sustainable future for our business and the planet.\n",
            "\n",
            "If you believe in better, we’ll back you all the way.\n",
            "\n",
            "Just so you know: if your application is successful, we’ll ask you to complete a criminal record check. And depending on the role you have applied for and the nature of any convictions you may have, we might have to withdraw the offer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### creating a list of cv and jd"
      ],
      "metadata": {
        "id": "PxeOvIvy7aH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=[cv,jd]"
      ],
      "metadata": {
        "id": "nhrGxUpu4epX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # library to count the occurence of each word\n",
        "from sklearn.metrics.pairwise import cosine_similarity # library to get the similarity between the jd and cv"
      ],
      "metadata": {
        "id": "dzg6ae_n4vnf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer()\n",
        "count_matrix=cv.fit_transform(text) "
      ],
      "metadata": {
        "id": "t1XME0R843Px"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(count_matrix)) # count matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVsOqlyJ5A4F",
        "outputId": "58a5f6d7-e255-49d8-d74d-bc19c672ab92"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.74594395]\n",
            " [0.74594395 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match=cosine_similarity(count_matrix)[0][1]\n",
        "match=match*100\n",
        "match=round(match,2)\n",
        "print(match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE1p-9Hu5QBP",
        "outputId": "65533a42-fcb9-4b1b-eee1-31117a54038b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(match>65):\n",
        "  print('application is accepted with',match,'match')\n",
        "else:\n",
        "  print('application is rejected with',match,'match')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH0iU6X65ifd",
        "outputId": "dfbdaa77-f125-46b2-f91a-b48e91da8067"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "application is accepted with 74.59 match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Thq_WaQ65tN6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}